Task 1:
Want to make predictions about how a user would rate a book in terms of star rating using the historical data.
The strategy I use is to use the latent factor model (prediction = alpha + bu + bi) to make prediction.
Where alpha is the global average of the book ratings. bu is the user bias on predicting books (how much the user's ratings typically deviate from the global average).
bi is the item bias on being predicted by different users (how much the item's ratings typically deviate from the global average).
The goodModel function runs the coordinate descent for 5 iterations to optimize these three parameters.

I first read the training data train_Interactions.csv.gz, and train the model with this data using the strategy.
And lastly generate the predictions and write it to predictions_Rating.csv.


Task 2:
Want to predict whether a user would read the specific book (0 or 1).
The strategy I use is the Jaccard similarity appoarch.
The Jaccard similarity is a simple formula that measures the overlap between these two sets:
Similarity = Size of Intersection / Size of Union
Where intersection is the number of users who read both "Book A" and "Book B". This is the "overlap" in your audience.
And union is the number of users who read at least one of the books ("Book A" or "Book B" or both). This is the "total" audience.
It checks if the target book (b) is similar to the other books the user (u) has read.
Similarity score is measured under the idea of "similar books are read by similar people."
For example, if _any_ book that the user (u) has already read is highly similar to the target book (b),
the model concludes that "this user likes books that are read by same people who read target book (b) -> predict 1.
It predicts 1 if the max similarity is above a threshold (0.013) or if the book is very popular (read more than 40 times).

I first implemented the jaccardThresh function to get the similarity of the target book and each of those books in the user's history.
And then generate the predictions and write it to predictions_Read.csv.


Task 3:
Want to predict the genre of the book based on the text of a review.
The strategy I use is the bag of words appoarch.
I first scan through all review texts in train_Category.json.gz to get the 2,000 most frequent words.
And turn each review into vector to count how many times each of the top words appear in that review.
Then use logistic regression model to train on the data and learn which words correspond to which genres.
Finally, process the test_Category.json.gz reviews using the same 2,000 word list, turn them into vectors,
and feed them to the trained model to get the predictions.
