{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c62c3f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffde3495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import homework3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e74ac9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df6d8628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46f18189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countRight(a,b,epsilon):\n",
    "    if len(a) != len(b):\n",
    "        print(\"It looks like your solution has the wrong length (got \" + str(len(a)) + \", expected \"\n",
    " + str(len(b)) + \")\")\n",
    "        return 0\n",
    "    a_ = np.array(a).flatten()\n",
    "    b_ = np.array(b).flatten()\n",
    "    right = np.abs(a_ - b_) < epsilon\n",
    "    return float(sum(right) / len(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b776b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data structures that will be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e79beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "for l in readCSV(\"../datasets/train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4103a0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9fe3a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c51f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Rating prediction                              #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef4c9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainRatings = [r[2] for r in ratingsTrain]\n",
    "globalAverage = homework3.getGlobalAverage(trainRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0332cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ1():\n",
    "    ga = homework3.getGlobalAverage(trainRatings)\n",
    "    trivialValidMSE = homework3.trivialValidMSE(ratingsValid, ga)\n",
    "    \n",
    "    print(\"average = \" + str(ga))\n",
    "    print(\"validation MSE = \" + str(trivialValidMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "413ce857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average = 3.6868052631578947\n",
      "validation MSE = 1.6802113179223874\n"
     ]
    }
   ],
   "source": [
    "testQ1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c109250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterateN(which, alpha, betaU, betaI, lamb, N):\n",
    "    for i in range(N):\n",
    "        alpha = which.alphaUpdate(ratingsTrain, alpha, betaU, betaI, lamb)\n",
    "        betaU = which.betaUUpdate(ratingsPerUser, alpha, betaU, betaI, lamb)\n",
    "        betaI = which.betaIUpdate(ratingsPerItem, alpha, betaU, betaI, lamb)\n",
    "        mse, mseReg = which.msePlusReg(ratingsTrain, alpha, betaU, betaI, lamb)\n",
    "        print(\"Iteration \" + str(i + 1))\n",
    "        print(\"  MSE = \" + str(mse))\n",
    "        print(\"  regularized objective = \" + str(mseReg))\n",
    "    return alpha, betaU, betaI, mse, mseReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68529957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(which):\n",
    "    betaU = {}\n",
    "    betaI = {}\n",
    "    for u in ratingsPerUser:\n",
    "        betaU[u] = 0\n",
    "\n",
    "    for b in ratingsPerItem:\n",
    "        betaI[b] = 0\n",
    "\n",
    "    alpha = globalAverage # Could initialize anywhere, this is a guess\n",
    "    \n",
    "    alpha, betaU, betaI, mse, mseReg = iterateN(which, alpha, betaU, betaI, 1.0, 1)\n",
    "    validMSE = which.validMSE(ratingsValid, alpha, betaU, betaI)\n",
    "    \n",
    "    return alpha, betaU, betaI, mse, mseReg, validMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9567547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ2():\n",
    "    alpha, betaU, betaI, mse, mseReg, validMSE = testModel(homework3)\n",
    "    print(\"validMSE = \" + str(validMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cac96b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "  MSE = 1.0727154704481001\n",
      "  regularized objective = 13249.828429085606\n",
      "validMSE = 1.440670105511256\n"
     ]
    }
   ],
   "source": [
    "testQ2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b673f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ3():\n",
    "    betaU = {}\n",
    "    betaI = {}\n",
    "    for u in ratingsPerUser:\n",
    "        betaU[u] = 0\n",
    "\n",
    "    for b in ratingsPerItem:\n",
    "        betaI[b] = 0\n",
    "\n",
    "    alpha = globalAverage # Could initialize anywhere, this is a guess\n",
    "    \n",
    "    alpha, betaU, betaI = homework3.goodModel(ratingsTrain, ratingsPerUser, ratingsPerItem, alpha, betaU, betaI)\n",
    "    validMSE = homework3.validMSE(ratingsValid, alpha, betaU, betaI)\n",
    "    \n",
    "    print(\"validMSE = \" + str(validMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3ea8135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validMSE = 1.4349771286465058\n"
     ]
    }
   ],
   "source": [
    "testQ3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddd75a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Read prediction                                #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac0c608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From baseline code\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"../datasets/train_Interactions.csv.gz\"):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "146f9c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ4():\n",
    "    readValid, notRead = homework3.generateValidation(allRatings, ratingsValid)\n",
    "    print(\"Should be equal: \" + str((len(readValid), len(notRead), len(ratingsValid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae0d6faa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'readValid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtestQ4\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mtestQ4\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtestQ4\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     readValid, notRead = \u001b[43mhomework3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerateValidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mallRatings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratingsValid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mShould be equal: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m((\u001b[38;5;28mlen\u001b[39m(readValid), \u001b[38;5;28mlen\u001b[39m(notRead), \u001b[38;5;28mlen\u001b[39m(ratingsValid))))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UCSD/Fall 2025/CSE158/hw3/homework3.py:214\u001b[39m, in \u001b[36mgenerateValidation\u001b[39m\u001b[34m(allRatings, ratingsValid)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerateValidation\u001b[39m(allRatings, ratingsValid):\n\u001b[32m    210\u001b[39m     \u001b[38;5;66;03m# Using ratingsValid, generate two sets:\u001b[39;00m\n\u001b[32m    211\u001b[39m     \u001b[38;5;66;03m# readValid: set of (u,b) pairs in the validation set\u001b[39;00m\n\u001b[32m    212\u001b[39m     \u001b[38;5;66;03m# notRead: set of (u,b') pairs, containing one negative (not read) for each row (u) in readValid  \u001b[39;00m\n\u001b[32m    213\u001b[39m     \u001b[38;5;66;03m# Both should have the same size as ratingsValid\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreadValid\u001b[49m, notRead\n",
      "\u001b[31mNameError\u001b[39m: name 'readValid' is not defined"
     ]
    }
   ],
   "source": [
    "testQ4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f241bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ5():\n",
    "    return1 = homework3.baseLineStrategy(mostPopular, totalRead)\n",
    "    better = homework3.improvedStrategy(mostPopular, totalRead)\n",
    "    \n",
    "    readValid, notRead = homework3.generateValidation(allRatings, ratingsValid)\n",
    "    \n",
    "    correctA = homework3.evaluateStrategy(return1, readValid, notRead)\n",
    "    correctB = homework3.evaluateStrategy(better, readValid, notRead)\n",
    "    \n",
    "    print(\"Accuracy (simple strategy) = \" + str(correctA))\n",
    "    print(\"Accuracy (better strategy) = \" + str(correctB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f729d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "testQ5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a29bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ6():\n",
    "    readValid, notRead = homework3.generateValidation(allRatings, ratingsValid)\n",
    "    \n",
    "    for (u,b) in list(readValid)[:20] + list(notRead)[:20]:\n",
    "        a = homework3.jaccardThresh(u,b,ratingsPerItem,ratingsPerUser)\n",
    "        print(\"Jaccard-based predictor for \" + str((u,b)) + \" = \" + str(a))\n",
    "\n",
    "    # This is slow (so the autograder doesn't run it) but you should run it at home once you have a good solution\n",
    "    #homework3.writePredictionsRead(ratingsPerItem, ratingsPerUser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "testQ6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1e31f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Category prediction                            #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aba9868",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for d in readGz(\"train_Category.json.gz\"):\n",
    "    data.append(d)\n",
    "    # Just use a little data to make things faster...\n",
    "    if len(data) > 10000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6a3a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review_text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e35313",
   "metadata": {},
   "outputs": [],
   "source": [
    "NW = 500 # dictionary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [x[1] for x in counts[:NW]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445775f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c5e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ7():\n",
    "    f1 = homework3.featureCat(data[0], words, wordId, wordSet)\n",
    "    \n",
    "    print(\"Feature vector = \" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb8ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "testQ7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8230c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQ8():\n",
    "    X = [homework3.featureCat(d, words, wordId, wordSet) for d in data]\n",
    "    y = [d['genreID'] for d in data]\n",
    "    \n",
    "    Xtrain = X[:9*len(X)//10]\n",
    "    ytrain = y[:9*len(y)//10]\n",
    "    Xvalid = X[9*len(X)//10:]\n",
    "    yvalid = y[9*len(y)//10:]\n",
    "    \n",
    "    mod = linear_model.LogisticRegression(C=1)\n",
    "    mod.fit(Xtrain, ytrain)\n",
    "    pred = mod.predict(Xvalid)\n",
    "    correctA = pred == yvalid\n",
    "    correctA = sum(correctA) / len(correctA)\n",
    "    \n",
    "    X = homework3.betterFeatures(data)\n",
    "    Xtrain = X[:9*len(X)//10]\n",
    "    Xvalid = X[9*len(X)//10:]\n",
    "    \n",
    "    mod = linear_model.LogisticRegression(C=1)\n",
    "    mod.fit(Xtrain, ytrain)\n",
    "    pred = mod.predict(Xvalid)\n",
    "    correctB = pred == yvalid\n",
    "    correctB = sum(correctB) / len(correctB)\n",
    "    \n",
    "    sc = correctA < (correctB * 0.99)\n",
    "\n",
    "    data_test = []\n",
    "    for d in readGz(\"test_Category.json.gz\"):\n",
    "        data_test.append(d)\n",
    "    \n",
    "    Xtest = homework3.betterFeatures(data_test)\n",
    "    pred_test = mod.predict(Xtest)\n",
    "    \n",
    "    homework3.writePredictionsCategory(pred_test)\n",
    "    \n",
    "    if sc:\n",
    "        print(\"Looks like your solution is better\")\n",
    "    else:\n",
    "        print(\"Looks like your solution is not better\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testQ8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681bd24a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse158",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
